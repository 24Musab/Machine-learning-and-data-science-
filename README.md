# Machine learning and data science 
This repository explain the difference between using the Hugging Face Trainer class and implementing a custom training loop for fine-tuning pretrained transformer model models. Additionally, it showcases how to utilize Optuna for hyperparameter tuning to optimize machine learning models performance.
